{"componentChunkName":"component---node-modules-carrotsearch-gatsby-theme-apidocs-templates-documentation-page-js","path":"/tuning-clustering/","result":{"data":{"site":{"siteMetadata":{"title":"Carrot2 docs","description":"User and developer manual for the Carrot2 text clustering engine.","lang":"en","indexAlias":"/hello-carrot2/"}},"html":{"frontmatter":{"id":"tuning-clustering","title":"Tuning clustering"},"html":"<article>\n  <h1>Tuning clustering</h1>\n\n  <p id=\"a63293e6\">\n    Carrot<sup>2</sup> algorithms should produce reasonably good clusters out-of-the\n    box for most inputs. If you'd like to fine-tune the quality or performance\n    of clustering, this article discusses the possible approaches.\n  </p>\n\n  <section id=\"input-characteristics\">\n    <h2>\n        <a class=\"anchor\" href=\"#input-characteristics\" aria-hidden=\"true\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Desirable characteristics of input\n      </h2>\n\n    <p id=\"input-characteristics:6563a872\">\n      The quality of clusters and their labels largely depends on the\n      quality of documents provided on the input. Although there is no\n      general rule for optimum document content, below are some tips worth\n      considering.\n    </p>\n\n    <ul>\n      <li>\n        <p id=\"input-characteristics:749bcd6e\">\n          <strong>Carrot<sup>2</sup> is designed for small to medium collections\n            of documents</strong>. Carrot<sup>2</sup> algorithms perform in-memory\n          clustering. For this reason, as a rule of thumb, Carrot<sup>2</sup>\n          should successfully deal with up to a thousand of documents, a few\n          paragraphs each. For algorithms designed to process millions of\n          documents, check out <a href=\"https://mahout.apache.org/\">the Apache Mahout project</a>\n          or <a href=\"https://carrotsearch.com/lingo4g/\">Carrot Search Lingo4G</a>.\n        </p>\n      </li>\n\n      <li>\n        <p id=\"input-characteristics:2ec6e48d\">\n          <strong>Provide a minimum of 100 documents</strong>. Carrot<sup>2</sup>\n          clustering algorithms work better with increasing amount of data. A hundred\n          documents on input is probably the minimum for any statistical significance\n          of features discovered by the algorithm. In general, an optimum number\n          of documents would probably fall between 100 and a few thousands.\n          More than that may cause problems due to in-memory processing.\n        </p>\n      </li>\n\n      <li>\n        <p id=\"input-characteristics:bddf9d4a\">\n          <strong>Provide query-context snippets instead of entire documents</strong>.\n          If the input\n          documents are a result of some search query, provide contextual\n          snippets related to that query (similar to what web search engines\n          return), instead of full document content. Not only will this speed up\n          processing, but should also guide the clustering algorithm to discover\n          query-related spectrum of topics.\n        </p>\n      </li>\n\n      <li>\n        <p id=\"input-characteristics:186c49f0\">\n          <strong>Minimize noise in the input documents</strong>. All kinds of noisy\n          fragments in the input like truncated sentences, random alphanumerical strings\n          or repeated boilerplate may decrease the quality of cluster labels.\n          If you are extracting query context for clustering, retrieving complete sentences\n          instead of truncated fragments should improve cluster labels even further.\n        </p>\n      </li>\n    </ul>\n  </section>\n\n  <section id=\"tuning-parameters\">\n    <h2>\n        <a class=\"anchor\" href=\"#tuning-parameters\" aria-hidden=\"true\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Tuning parameters\n      </h2>\n\n    <p id=\"tuning-parameters:f696ffbd\">\n      The default settings that come with each algorithm are good for an average case. Each\n      clustering algorithm comes with a number of parameters affecting its output and\n      runtime characteristics. See the algorithm's reference page, such as\n      <a href=\"/lingo-parameters/\">Lingo parameters</a>, for a list and\n      description of the parameters.\n    </p>\n\n\n    <p id=\"tuning-parameters:39d95a82\">\n      You can easily <a href=\"/java-api-basics/#tweaking-parameters\">adjust\n      parameters in Java API</a>. If you call the REST API from Java code,\n      a robust way to override parameters is to\n      <a href=\"/rest-api-basics/#models\">use request model classes</a>.\n    </p>\n\n    <p id=\"tuning-parameters:workbench:tuning-parameters:workbench\">\n      When using the REST API directly, an easy way to get the parameters JSON\n      object is to use Carrot<sup>2</sup> Workbench: set the desired values\n      using the left-hand-side panel and then press the parameter export button\n      to get the JSON with just the parameters that are different from defaults.\n    </p>\n\n    <figure>\n      <div class=\"img\" style=\"position: relative\"><span style=\"padding-bottom: 56.111111111111114%; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAABuElEQVQozzWSW2/UMBBG9y8BEtBWrUDiAfGExK9nW2Wz6zTx3Y6vYyd2IMnmk59GczSa4zk9f/v+93weBsyE4EpJKbiQXAhjDACkBDnneUspJYQgtUkp1VpzzqcPHz8h1HEhRmuMddYozpnWuta6LEsCLwWfpmlZllqrUgpjzDnPW06fvz4yxoQaMSGUUoCYc04pAcA0zcGPQ/+eUtphzjlCqO97SukGPzy1bSuk5uPo9biUsvWVBMn5AMEyRgAOWIgb6m632z58hV9f34wx0jkm5TTPy5ZaawjBO911N2vdXhFCEIKHYdBaT9O0wggh74MH0MbUbfLe6r0PwRCCY4x7ZTRWaQ2Qy5Y7HEKYSkkxLge82ko5+LHvuxDusFaCUso59d6v8JeHp6ZptNYRkvU+5xyCj7D+EECKweChPyYvShKCe62Ec3bd+fH55fzWXC4NoWwcjTUKDz3nHABKqTFYzli5W1yFoa5DCF2vV+/96dfvP5gQRikhxDkP0fb9O2Ns3sxFP1KC58MiJaRpmuZyadvWOXd6+fGTc26tlVIaYwHi9tJ+JGWeYozlEJFzjjFul5f+7/wPAP1b9ZYpQKoAAAAASUVORK5CYII=')\" class=\"preview light\"> </span><img class=\"light\" alt=\"Carrot2 Workbench, parameter JSON export, light theme.\" title=\"\" src=\"../static/72a25f4f5c6ea22bd3b9b3e6cd8981af/eefce/carrot2-workbench-parameter-json-light.png\" srcset=\"../static/72a25f4f5c6ea22bd3b9b3e6cd8981af/dfaee/carrot2-workbench-parameter-json-light.png 180w,\n../static/72a25f4f5c6ea22bd3b9b3e6cd8981af/4d463/carrot2-workbench-parameter-json-light.png 360w,\n../static/72a25f4f5c6ea22bd3b9b3e6cd8981af/eefce/carrot2-workbench-parameter-json-light.png 720w,\n../static/72a25f4f5c6ea22bd3b9b3e6cd8981af/dabea/carrot2-workbench-parameter-json-light.png 1080w,\n../static/72a25f4f5c6ea22bd3b9b3e6cd8981af/87339/carrot2-workbench-parameter-json-light.png 1440w,\n../static/72a25f4f5c6ea22bd3b9b3e6cd8981af/022a0/carrot2-workbench-parameter-json-light.png 3840w\" sizes=\"(max-width: 720px) 100vw, 720px\"></div>\n      <div class=\"img\" style=\"position: relative\"><span style=\"padding-bottom: 56.111111111111114%; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB+ElEQVQozzXSCZKbMBAFUE6RmkxmKBuzS0IrIFaJzTZgsGdPKve/R4o4OcCr3/27jb0bxlUvyr44v6nlV1z2SFQkqQGTDuQu5DZgVkCsgBwCAlgGeGkDvvMiL0qMb49PtOho3iLZ4nzgmSJpBUWx8/GzDf2Ik7Q8hPTZBi7k7WmlsmZSmS5qz4vx3bQcJEg11pevcvoQ7UrVTPVFdNcwbUMcp2XnQL5hxIfpJvImrTrI89PyZjyYByQKpud8/V2d3plesV5os8rzB6snP+IsUw4Ud9xPN1G0hT4GJD1dXo0H06J5w9WUTF/Z/MXaK9ELVhfWXrkaAYkzNYRU/sdXnFRJ1blIDPPLhoEoSHkSp7f0/M6a5Y55dxN6DiIeF40Xxc828JBQwyUg0oviRyvop9tfzAtaj3x4lf0L1xsmemHtDWZ9iIWs+zve0sY1SgqRKyvA/XjdME4VKY9EX0iz4GrawtWM69njdYh5UjYu2rAD+Xm+clmTZOt/2/nH3mPlkDcjEJUTJR4SLNNQFFZITTcKsWCy3m9n+1dYXDS5Poq8mW+fBiA8ZDmVmkjtRImPmKw7mikrIE82ACTmmbYCch97XN8zNdT9JPJmef1p7BzfjRKfZIDlHk4OIXGRcOD2Q6YDrQC7SOx9bDpw72PIpA2Yi8QhpIDJP8fhimCDWimZAAAAAElFTkSuQmCC')\" class=\"preview dark\"> </span><img class=\"dark\" alt=\"Carrot2 Workbench, parameter JSON export, dark theme.\" title=\"\" src=\"../static/ccc0a54971be14bc9c540e4ce2205c23/eefce/carrot2-workbench-parameter-json-dark.png\" srcset=\"../static/ccc0a54971be14bc9c540e4ce2205c23/dfaee/carrot2-workbench-parameter-json-dark.png 180w,\n../static/ccc0a54971be14bc9c540e4ce2205c23/4d463/carrot2-workbench-parameter-json-dark.png 360w,\n../static/ccc0a54971be14bc9c540e4ce2205c23/eefce/carrot2-workbench-parameter-json-dark.png 720w,\n../static/ccc0a54971be14bc9c540e4ce2205c23/dabea/carrot2-workbench-parameter-json-dark.png 1080w,\n../static/ccc0a54971be14bc9c540e4ce2205c23/87339/carrot2-workbench-parameter-json-dark.png 1440w,\n../static/ccc0a54971be14bc9c540e4ce2205c23/022a0/carrot2-workbench-parameter-json-dark.png 3840w\" sizes=\"(max-width: 720px) 100vw, 720px\"></div>\n      <figcaption>\n        <p>\n          Exporting parameters JSON in Carrot<sup>2</sup> Workbench.\n        </p>\n      </figcaption>\n    </figure>\n  </section>\n\n  <section id=\"tuning-language-resources\">\n    <h2>\n        <a class=\"anchor\" href=\"#tuning-language-resources\" aria-hidden=\"true\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Tuning language resources\n      </h2>\n\n    <p id=\"tuning-language-resources:d4bc8bd2\">\n      In order to achieve good cluster labels and high clustering quality it is vital\n      to <strong>adjust the default language resources</strong> so that they exclude any common\n      terms, phrases and expressions specific to:\n    </p>\n\n    <ul>\n      <li>\n        <p id=\"tuning-language-resources:811122a8\">\n          the selected language, including function words such as\n          <em>for</em> or <em>between</em> (the default resources should contain\n          a reasonable number of these already);\n        </p>\n      </li>\n      <li>\n        <p id=\"tuning-language-resources:3b151767\">\n          the domain of documents being clustered.\n        </p>\n      </li>\n    </ul>\n\n    <p id=\"tuning-language-resources:c8dca7de\">\n      For example, if clustering documents from the medical domain, certain expressions and terms\n      may be obvious and trivial to the domain. Forming clusters out of these wouldn't be of any\n      value to the users. By excluding such expressions the algorithms are guided to look for other,\n      perhaps more interesting alternative content.\n    </p>\n\n    <p id=\"tuning-language-resources:8592e938\">\n      Language resources can be adjusted in many ways. See the relevant\n      bits of documentation in the <a href=\"/java-language-components/\">Java API</a>,\n      the <a href=\"/dcs-language-components/\">REST API</a> and\n      word and label <a href=\"/dictionaries/\">filtering dictionary syntax</a>.\n    </p>\n  </section>\n\n  <section id=\"performance-tuning\">\n    <h2>\n        <a class=\"anchor\" href=\"#performance-tuning\" aria-hidden=\"true\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Performance tuning\n      </h2>\n\n    <p id=\"performance-tuning:9deb13ad\">\n      Carrot<sup>2</sup> clustering algorithms have been designed to work really fast\n      but the trade-off is that they store all the data structures in memory.\n      The size of the Java virtual machine's heap will increase quickly\n      with longer overall size of input text. Also, the more documents you put on input and the longer\n      the documents are, the longer the clustering will take.\n    </p>\n\n    <p id=\"performance-tuning:54175c85\">\n      Below are a few generic guidelines on improving clustering performance.\n    </p>\n\n    <section id=\"reduce-input-size\">\n      <h3>\n        <a class=\"anchor\" href=\"#reduce-input-size\" aria-hidden=\"true\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reduce size of input\n      </h3>\n\n      <p id=\"reduce-input-size:bbae20a7\">\n        In many cases clustering short document excerpts may work just as well or\n        even better than full documents. Consider the possibility of replacing\n        full content with:\n      </p>\n\n      <ul>\n        <li id=\"reduce-input-size:cf76c093\">query-matching document fragments (such as search result snippets), if input documents\n          are a result of some type of user-entered query,\n        </li>\n        <li id=\"reduce-input-size:3cfbb212\">titles and abstracts of documents, if they are available,</li>\n        <li id=\"reduce-input-size:00b3d57e\">just the leading few sentences or paragraphs of each document.</li>\n      </ul>\n    </section>\n\n    <section id=\"batch-and-merge\">\n      <h3>\n        <a class=\"anchor\" href=\"#batch-and-merge\" aria-hidden=\"true\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Batch and merge smaller clustering runs\n      </h3>\n\n      <p id=\"batch-and-merge:3ec37c8a\">\n        In many cases when the input collection of documents is too large to cluster as a whole,\n        dividing the input into smaller batches (or sampling smaller batches from the input), then\n        clustering separately and finally merging\n        based on cluster label text gives very reasonable results.\n      </p>\n\n      <p id=\"batch-and-merge:570695b5\">\n        The above approach works because cluster labels recurring in smaller batches are very likely\n        to be significant for the entire collection. The downside is that\n        very small clusters containing just a few documents are likely to be lost during this process.\n      </p>\n    </section>\n\n    <section id=\"tune-algorithm\">\n      <h3>\n        <a class=\"anchor\" href=\"#tune-algorithm\" aria-hidden=\"true\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Tune algorithm parameters\n      </h3>\n\n      <p id=\"tune-algorithm:d5b0a58a\">\n        In many cases the default parameter settings for each algorithm may not be suitable for very\n        large inputs. Below are some parameter customization suggestions you should consider. You will\n        likely need to experiment a bit to adjust their values to match the size of your particular input.\n      </p>\n\n      <section>\n        <h4>STC, Bisecting k-Means</h4>\n\n        <section>\n          <h5><code>wordDfThreshold</code></h5>\n\n          <p id=\"tune-algorithm:2cc93d01\">\n            Increase the minimum document frequency (minimum number of\n            occurrences) of terms and phrases to a higher value. Something like\n            0.5% of the number of documents will typically work. For example, for\n            a document collection of 5000 documents set the parameter to 25.\n          </p>\n        </section>\n      </section>\n\n      <section>\n        <h4>Lingo</h4>\n\n        <section>\n          <h5><code>wordDfThreshold</code>, <code>phraseDfThreshold</code></h5>\n\n          <p id=\"tune-algorithm:2cc93d01_0\">\n            Increase the minimum document frequency (minimum number of\n            occurrences) of terms and phrases to a higher value. Something like\n            0.5% of the number of documents will typically work. For example, for\n            a document collection of 5000 documents set the parameter to 25.\n          </p>\n        </section>\n\n        <section>\n          <h5><code>factorizationQuality</code></h5>\n\n          <p id=\"tune-algorithm:d9595481\">\n            For <code>algorithm.matrixReducer.factorizationFactory</code> implementations that support\n            this parameter, lower <code>factorizationQuality</code>. This will cause the\n            matrix factorization algorithm to perform fewer iterations and hence complete quicker.\n          </p>\n          <p id=\"tune-algorithm:5a51ed80\">\n            Alternatively, you can set <code>algorithm.matrixReducer.factorizationFactory</code>\n            to an implementation of <code>PartialSingularValueDecompositionFactory</code>, which is\n            slightly faster than the other factorizations and does not have\n            any explicit <code>factorizationQuality</code> parameter.\n          </p>\n        </section>\n\n        <section>\n          <h5><code>maximumMatrixSize</code></h5>\n\n          <p id=\"tune-algorithm:73ddd41e\">\n            Lower maximum matrix size in <code>matrixBuilder</code>. This will cause the matrix\n            factorization algorithm to complete quicker and use less memory. The tradeoff is that with\n            small matrix sizes, Lingo may not be able to discover smaller clusters.\n          </p>\n        </section>\n      </section>\n    </section>\n  </section>\n</article>","tableOfContents":[{"heading":"Desirable characteristics of input","anchor":"input-characteristics"},{"heading":"Tuning parameters","anchor":"tuning-parameters"},{"heading":"Tuning language resources","anchor":"tuning-language-resources"},{"heading":"Performance tuning","anchor":"performance-tuning","sections":[{"heading":"Reduce size of input","anchor":"reduce-input-size"},{"heading":"Batch and merge smaller clustering runs","anchor":"batch-and-merge"},{"heading":"Tune algorithm parameters","anchor":"tune-algorithm"}]}]}},"pageContext":{"slug":"/tuning-clustering/"}},"staticQueryHashes":["2081922839"]}